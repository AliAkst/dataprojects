{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "5e3a8b7ec89f1a235ff15d33d91b7370891c708cfdc79760290db24a4cbd8f1c"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# **Hands-on Practice Lab: Data Wrangling**\n\nEstimated time needed: **30** minutes\n\nIn this lab, you will use the skills acquired in the module and address the issues of handling missing data, correct the data type of the dataframe attribute and execute the processes of data standardization and data normalization on specific attributes of the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Objectives\n\nAfter completing this lab you will be able to:\n\n - Handle missing data in different ways\n - Correct the data type of different data values as per requirement\n - Standardize and normalize the appropriate data attributes\n - Visualize the data as grouped bar graph using Binning\n - Cnverting a categorical data into numerical indicator variables\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Setup\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For this lab, we will be using the following libraries:\n\n* `skillsnetwork` to download the dataset\n*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Importing Required Libraries\n\n_We recommend you import all required libraries in one place (here):_\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-1-51e788afe6f2>:2: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "Download the updated dataset by running the cell below.\n\nThe functions below will download the dataset into your browser:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "file_path= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod1.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "To obtain the dataset, utilize the download() function as defined above:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "await download(file_path, \"laptops.csv\")\nfile_name=\"laptops.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "First we load data into a `pandas.DataFrame`:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(file_name, header=0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "> Note: This version of the lab is working on JupyterLite, which requires the dataset to be downloaded to the interface.While working on the downloaded version of this notebook on their local machines(Jupyter Anaconda), the learners can simply **skip the steps above,** and simply use the URL directly in the `pandas.read_csv()` function. You can uncomment and run the statements in the cell below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#filepath = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod1.csv\"\n#df = pd.read_csv(filepath, header=None)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "Verify loading by displaying the dataframe summary using `dataframe.info()`\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(df.info())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 238 entries, 0 to 237\nData columns (total 13 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   Unnamed: 0      238 non-null    int64  \n 1   Manufacturer    238 non-null    object \n 2   Category        238 non-null    int64  \n 3   Screen          238 non-null    object \n 4   GPU             238 non-null    int64  \n 5   OS              238 non-null    int64  \n 6   CPU_core        238 non-null    int64  \n 7   Screen_Size_cm  234 non-null    float64\n 8   CPU_frequency   238 non-null    float64\n 9   RAM_GB          238 non-null    int64  \n 10  Storage_GB_SSD  238 non-null    int64  \n 11  Weight_kg       233 non-null    float64\n 12  Price           238 non-null    int64  \ndtypes: float64(3), int64(8), object(2)\nmemory usage: 22.4+ KB\nNone\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "View the first 5 values of the updated dataframe using `dataframe.head()`\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Unnamed: 0 Manufacturer  Category     Screen  GPU  OS  CPU_core  \\\n0           0         Acer         4  IPS Panel    2   1         5   \n1           1         Dell         3    Full HD    1   1         3   \n2           2         Dell         3    Full HD    1   1         7   \n3           3         Dell         4  IPS Panel    2   1         5   \n4           4           HP         4    Full HD    2   1         7   \n\n   Screen_Size_cm  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_kg  Price  \n0          35.560            1.6       8             256       1.60    978  \n1          39.624            2.0       4             256       2.20    634  \n2          39.624            2.7       8             256       2.20    946  \n3          33.782            1.6       8             128       1.22   1244  \n4          39.624            1.8       8             256       1.91    837  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Manufacturer</th>\n      <th>Category</th>\n      <th>Screen</th>\n      <th>GPU</th>\n      <th>OS</th>\n      <th>CPU_core</th>\n      <th>Screen_Size_cm</th>\n      <th>CPU_frequency</th>\n      <th>RAM_GB</th>\n      <th>Storage_GB_SSD</th>\n      <th>Weight_kg</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Acer</td>\n      <td>4</td>\n      <td>IPS Panel</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>35.560</td>\n      <td>1.6</td>\n      <td>8</td>\n      <td>256</td>\n      <td>1.60</td>\n      <td>978</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>Full HD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>39.624</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>256</td>\n      <td>2.20</td>\n      <td>634</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>Full HD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>39.624</td>\n      <td>2.7</td>\n      <td>8</td>\n      <td>256</td>\n      <td>2.20</td>\n      <td>946</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Dell</td>\n      <td>4</td>\n      <td>IPS Panel</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>33.782</td>\n      <td>1.6</td>\n      <td>8</td>\n      <td>128</td>\n      <td>1.22</td>\n      <td>1244</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>HP</td>\n      <td>4</td>\n      <td>Full HD</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>39.624</td>\n      <td>1.8</td>\n      <td>8</td>\n      <td>256</td>\n      <td>1.91</td>\n      <td>837</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "Note that we can update the `Screen_Size_cm` column such that all values are rounded to nearest 2 decimal places by using `numpy.round()`\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df[['Screen_Size_cm']] = np.round(df[['Screen_Size_cm']],2)\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Unnamed: 0 Manufacturer  Category     Screen  GPU  OS  CPU_core  \\\n0           0         Acer         4  IPS Panel    2   1         5   \n1           1         Dell         3    Full HD    1   1         3   \n2           2         Dell         3    Full HD    1   1         7   \n3           3         Dell         4  IPS Panel    2   1         5   \n4           4           HP         4    Full HD    2   1         7   \n\n   Screen_Size_cm  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_kg  Price  \n0           35.56            1.6       8             256       1.60    978  \n1           39.62            2.0       4             256       2.20    634  \n2           39.62            2.7       8             256       2.20    946  \n3           33.78            1.6       8             128       1.22   1244  \n4           39.62            1.8       8             256       1.91    837  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Manufacturer</th>\n      <th>Category</th>\n      <th>Screen</th>\n      <th>GPU</th>\n      <th>OS</th>\n      <th>CPU_core</th>\n      <th>Screen_Size_cm</th>\n      <th>CPU_frequency</th>\n      <th>RAM_GB</th>\n      <th>Storage_GB_SSD</th>\n      <th>Weight_kg</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Acer</td>\n      <td>4</td>\n      <td>IPS Panel</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>35.56</td>\n      <td>1.6</td>\n      <td>8</td>\n      <td>256</td>\n      <td>1.60</td>\n      <td>978</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>Full HD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>39.62</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>256</td>\n      <td>2.20</td>\n      <td>634</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>Full HD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>39.62</td>\n      <td>2.7</td>\n      <td>8</td>\n      <td>256</td>\n      <td>2.20</td>\n      <td>946</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Dell</td>\n      <td>4</td>\n      <td>IPS Panel</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>33.78</td>\n      <td>1.6</td>\n      <td>8</td>\n      <td>128</td>\n      <td>1.22</td>\n      <td>1244</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>HP</td>\n      <td>4</td>\n      <td>Full HD</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>39.62</td>\n      <td>1.8</td>\n      <td>8</td>\n      <td>256</td>\n      <td>1.91</td>\n      <td>837</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 1\n\n### Evaluate the dataset for missing data\nMissing data was last converted from '?' to numpy.NaN. Pandas uses NaN and Null values interchangeably. This means, you can just identify the entries having Null values. Write a code that identifies which columns have missing data. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute \nmissing_data = df.isnull()\nprint(missing_data.head())\nfor column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\") ",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "   Unnamed: 0  Manufacturer  Category  Screen    GPU     OS  CPU_core  \\\n0       False         False     False   False  False  False     False   \n1       False         False     False   False  False  False     False   \n2       False         False     False   False  False  False     False   \n3       False         False     False   False  False  False     False   \n4       False         False     False   False  False  False     False   \n\n   Screen_Size_cm  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_kg  Price  \n0           False          False   False           False      False  False  \n1           False          False   False           False      False  False  \n2           False          False   False           False      False  False  \n3           False          False   False           False      False  False  \n4           False          False   False           False      False  False  \nUnnamed: 0\nUnnamed: 0\nFalse    238\nName: count, dtype: int64\n\nManufacturer\nManufacturer\nFalse    238\nName: count, dtype: int64\n\nCategory\nCategory\nFalse    238\nName: count, dtype: int64\n\nScreen\nScreen\nFalse    238\nName: count, dtype: int64\n\nGPU\nGPU\nFalse    238\nName: count, dtype: int64\n\nOS\nOS\nFalse    238\nName: count, dtype: int64\n\nCPU_core\nCPU_core\nFalse    238\nName: count, dtype: int64\n\nScreen_Size_cm\nScreen_Size_cm\nFalse    234\nTrue       4\nName: count, dtype: int64\n\nCPU_frequency\nCPU_frequency\nFalse    238\nName: count, dtype: int64\n\nRAM_GB\nRAM_GB\nFalse    238\nName: count, dtype: int64\n\nStorage_GB_SSD\nStorage_GB_SSD\nFalse    238\nName: count, dtype: int64\n\nWeight_kg\nWeight_kg\nFalse    233\nTrue       5\nName: count, dtype: int64\n\nPrice\nPrice\nFalse    238\nName: count, dtype: int64\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 2\n\n### Replace with mean\nMissing values in attributes that have continuous data are best replaced using Mean value. We note that values in \"Weight_kg\" attribute are continuous in nature, and some values are missing. Therefore, write a code to replace the missing values of weight with the average value of the attribute.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\navg_weight=df['Weight_kg'].astype('float').mean(axis=0)\ndf[\"Weight_kg\"].replace(np.nan, avg_weight, inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-14-82df52102428>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[\"Weight_kg\"].replace(np.nan, avg_weight, inplace=True)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": "### Replace with the most frequent value\nMissing values in attributes that have categorical data are best replaced using the most frequent value. We note that values in \"Screen_Size_cm\" attribute are categorical in nature, and some values are missing. Therefore, write a code to replace the missing values of Screen Size with the most frequent value of the attribute.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\ncommon_screen_size = df['Screen_Size_cm'].value_counts().idxmax()\ndf[\"Screen_Size_cm\"].replace(np.nan, common_screen_size, inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 3\n\n### Fixing the data types\nBoth \"Weight_kg\" and \"Screen_Size_cm\" are seen to have the data type \"Object\", while both of them should be having a data type of \"float\". Write a code to fix the data type of these two columns.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\n\ndf[[\"Weight_kg\",\"Screen_Size_cm\"]] = df[[\"Weight_kg\",\"Screen_Size_cm\"]].astype(\"float\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 4\n\n### Data Standardization\nThe value of Screen_size usually has a standard unit of inches. Similarly, weight of the laptop is needed to be in pounds. Use the below mentioned units of conversion and write a code to modify the columns of the dataframe accordingly. Update their names as well.\n\n```{math}\n1 inch = 2.54 cm\n1 kg   = 2.205 pounds\n```\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\ndf[\"Weight_kg\"] = df[\"Weight_kg\"]*2.205\ndf.rename(columns={'Weight_kg':'Weight_pounds'}, inplace=True)\n\n# Data standardization: convert screen size from cm to inch\ndf[\"Screen_Size_cm\"] = df[\"Screen_Size_cm\"]/2.54\ndf.rename(columns={'Screen_Size_cm':'Screen_Size_inch'}, inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": "### Data Normalization\nOften it is required to normalize a continuous data attribute. Write a code to normalize the \"CPU_frequency\" attribute with respect to the maximum value available in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\ndf['CPU_frequency'] = df['CPU_frequency']/df['CPU_frequency'].max()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 5\n\n### Binning\nBinning is a process of creating a categorical attribute which splits the values of a continuous data into a specified number of groups. In this case, write a code to create 3 bins for the attribute \"Price\". These bins would be named \"Low\", \"Medium\" and \"High\". The new attribute will be named \"Price-binned\".\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\nbins = np.linspace(min(df[\"Price\"]), max(df[\"Price\"]), 4)\ngroup_names = ['Low', 'Medium', 'High']\ndf['Price-binned'] = pd.cut(df['Price'], bins, labels=group_names, include_lowest=True )",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n    <summary>Click here for Solution</summary>\n\n```python\nbins = np.linspace(min(df[\"Price\"]), max(df[\"Price\"]), 4)\ngroup_names = ['Low', 'Medium', 'High']\ndf['Price-binned'] = pd.cut(df['Price'], bins, labels=group_names, include_lowest=True )\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Also, plot the bar graph of these bins.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\nplt.bar(group_names, df[\"Price-binned\"].value_counts())\nplt.xlabel(\"Price\")\nplt.ylabel(\"\")\nplt.title(\"\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n    <summary>Click here for Solution</summary>\n\n```python\nplt.bar(group_names, df[\"Price-binned\"].value_counts())\nplt.xlabel(\"Price\")\nplt.ylabel(\"count\")\nplt.title(\"Price bins\")\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 6\n\n### Indicator variables\nConvert the \"Screen\" attribute of the dataset into 2 indicator variables, \"Screen-IPS_panel\" and \"Screen-Full_HD\". Then drop the \"Screen\" attribute from the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n    <summary>Click here for Solution</summary>\n\n```python\n#Indicator Variable: Screen\ndummy_variable_1 = pd.get_dummies(df[\"Screen\"])\ndummy_variable_1.rename(columns={'IPS Panel':'Screen-IPS_panel', 'Full HD':'Screen-Full_HD'}, inplace=True)\ndf = pd.concat([df, dummy_variable_1], axis=1)\n\n# drop original column \"Screen\" from \"df\"\ndf.drop(\"Screen\", axis = 1, inplace=True)\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This version of the dataset, now finalized, is the one you'll be using in all subsequent modules. \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Print the content of dataframe.head() to verify the changes that were made to the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(df.head())",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Congratulations! You have completed the lab\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Abhishek Gagneja](https://www.coursera.org/instructor/~129186572)\n\n[Vicky Kuo](https://author.skills.network/instructors/vicky_kuo)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright © 2023 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-09-15|0.1|Abhishek Gagneja|Initial Version Created|\n|2023-09-19|0.2|Vicky Kuo|Reviewed and Revised| --!>\n",
      "metadata": {}
    }
  ]
}